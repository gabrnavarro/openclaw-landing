1:"$Sreact.fragment"
2:I[22016,["/openclaw-landing/_next/static/chunks/744355e03808d4c7.js","/openclaw-landing/_next/static/chunks/7c92e96509cd355e.js"],""]
7:I[97367,["/openclaw-landing/_next/static/chunks/ff1a16fafef87110.js","/openclaw-landing/_next/static/chunks/d2be314c3ece3fbe.js"],"OutletBoundary"]
8:"$Sreact.suspense"
3:T1279,<p>At work, we experienced an issue with Jenkins builds starting to randomly fail on the slaves
with a pretty obscure error:</p>
<blockquote>
<p>OCI runtime create failed: container_linux.go:345:
starting container process caused "process_linux.go:424: container init caused "join session keyring: create session
key: disk quota exceeded"": unknown</p>
</blockquote>
<p>We aggresively use docker images to build and deploy artifacts as well as run various scripts. Almost every shell script is run inside a docker container to make sure that the configuration of the "machines" are the same for all runs. This means we have hundreds of containers in the slaves, although most of them are not really running.</p>
<p>One morning, everything started to break, and our deploy jobs were affected, so I sprung into action and took a look.</p>
<h2>Disk quota?</h2>
<p>At first glance, the error looked like a disk issue, so by instinct, I first checked whether the disk in one of the slaves was full.</p>
<pre><code>jenkins@ip:~$ df -h
Filesystem      Size  Used Avail Use% Mounted on
udev             16G     0   16G   0% /dev
tmpfs           3.1G  584K  3.1G   1% /run
/dev/nvme1n1p1  7.7G  2.0G  5.7G  26% /
tmpfs            16G     0   16G   0% /dev/shm
tmpfs           5.0M     0  5.0M   0% /run/lock
tmpfs            16G     0   16G   0% /sys/fs/cgroup
/dev/nvme0n1p3   28G   13G   15G  47% /home/jenkins
/dev/nvme0n1p2   84G  8.5G   76G  11% /var/lib/docker
overlay          84G  8.5G   76G  11% /var/lib/docker/1001.1001/overlay2/8ec5fac4206d1918bda2f/merged
shm              64M     0   64M   0% /var/lib/docker/1001.1001/containers/c61c68c4c23b8841e468a/mounts/shm
tmpfs           3.1G     0  3.1G   0% /run/user/1001
</code></pre>
<p>There was nothing unusual in particular here, as no disks were really full. Next, I checked the inode usage.</p>
<pre><code>jenkins@ip:~$ df -ih
Filesystem     Inodes IUsed IFree IUse% Mounted on
udev             3.9M   335  3.9M    1% /dev
tmpfs            3.9M   561  3.9M    1% /run
/dev/nvme1n1p1  1000K  107K  894K   11% /
tmpfs            3.9M     1  3.9M    1% /dev/shm
tmpfs            3.9M     3  3.9M    1% /run/lock
tmpfs            3.9M    18  3.9M    1% /sys/fs/cgroup
/dev/nvme0n1p3    14M  430K   14M    4% /home/jenkins
/dev/nvme0n1p2    42M  254K   42M    1% /var/lib/docker
overlay           42M  254K   42M    1% /var/lib/docker/1001.1001/overlay2/8ec5fac41918bda2f/merged
shm              3.9M     1  3.9M    1% /var/lib/docker/1001.1001/containers/c61c6877e16063d7f9757f0a568fa5c4c23b8841e468a/mounts/shm
tmpfs            3.9M    10  3.9M    1% /run/user/1001
</code></pre>
<p>Hmm. Nothing unusual as well. If the disk wasn't full, there must be a config somewhere that's limiting it, so I took a second look at the error
message for more clues.</p>
<blockquote>
<p>"join session keyring: create session key:</p>
</blockquote>
<h2>Keyrings</h2>
<p>It looked like some type of resource related to keyrings reached its limit, so I looked at the keyring limits and how many were running.</p>
<pre><code>jenkins@ip:~$ cat /proc/sys/kernel/keys/maxkeys
1000000
jenkins@ip-:~$ cat /proc/sys/kernel/keys/root_maxkeys 
1000000
jenkins@ip:~$ cat /proc/keys | wc -l
243
</code></pre>
<p>The limits are large enough, and the keys are also pretty small relative to it. At this point, I got pretty stumped, until I read the <code>keyrings(7)</code>
manual and found another interesting config:</p>
<blockquote>
<p>/proc/sys/kernel/keys/maxbytes (since Linux 2.6.26)
This is the maximum number of bytes of data that a nonroot
user can hold in the payloads of the keys owned by the user.</p>
<p>The default value in this file is 20,000.</p>
</blockquote>
<p>So i checked it.</p>
<pre><code>jenkins@ip4:~$ cat /proc/sys/kernel/keys/maxbytes
20000
</code></pre>
<p>Aha. That limit is pretty low, considering we have about 243 keyrings. So I bumped it up to about 50mb. Turns out it was actually the issue,
and have found similar issues after some deep googling. Two things/bugs i learned:</p>
<ul>
<li><a href="https://github.com/opencontainers/runc/pull/582">The default limit for number of keyrings is high, but the disk space they can use is extremely low</a></li>
<li><a href="https://github.com/opencontainers/runc/issues/726">A unique session key is created for every linux container</a> which was why the issue only happened when there were too many containers in the slaves already.</li>
</ul>
<h2>TLDR;/ Solution</h2>
<p>We mitigated the issue by pruning the containers first using <code>docker prune -f a</code>, or <code>docker container prune</code>, then we set the correct limit by editing the config.</p>
<pre><code>echo "52428800" > /proc/sys/keys/maxbytes
</code></pre>
0:{"buildId":"Ans0bDqDZY5xoXeZctdt3","rsc":["$","$1","c",{"children":[["$","div",null,{"className":"min-h-screen bg-white text-neutral-950","children":[["$","div",null,{"className":"pointer-events-none fixed inset-0 -z-10","children":[["$","div",null,{"className":"absolute inset-0 bg-gradient-to-b from-white via-white to-zinc-50"}],["$","div",null,{"className":"absolute left-1/2 top-[-240px] h-[520px] w-[520px] -translate-x-1/2 rounded-full bg-blue-200/35 blur-3xl"}],["$","div",null,{"className":"absolute left-[20%] top-[240px] h-[420px] w-[420px] rounded-full bg-emerald-200/25 blur-3xl"}]]}],["$","main",null,{"className":"mx-auto w-full max-w-3xl px-6 py-16 sm:py-20","children":[["$","div",null,{"className":"flex items-center justify-between","children":[["$","$L2",null,{"href":"/blog","className":"inline-flex h-10 items-center justify-center rounded-full border border-neutral-200 bg-white px-4 text-sm font-medium text-neutral-900 shadow-sm transition hover:bg-neutral-50","children":"← Blog"}],["$","$L2",null,{"href":"/","className":"inline-flex h-10 items-center justify-center rounded-full border border-neutral-200 bg-white px-4 text-sm font-medium text-neutral-900 shadow-sm transition hover:bg-neutral-50","children":"Home"}]]}],["$","article",null,{"className":"mt-10 overflow-hidden rounded-3xl border border-neutral-200 bg-white shadow-sm","children":[["$","header",null,{"className":"border-b border-neutral-100 p-6 sm:p-8","children":[["$","div",null,{"className":"text-xs text-neutral-500","children":"April 04, 2020"}],["$","h1",null,{"className":"mt-2 text-3xl font-semibold tracking-tight","children":"Disk quota exceeded error in docker containers"}],["$","div",null,{"className":"mt-4 flex flex-wrap gap-2","children":[["$","span","docker",{"className":"rounded-full border border-neutral-200 bg-white px-2.5 py-1 text-[11px] text-neutral-700","children":"docker"}],["$","span","jenkins",{"className":"rounded-full border border-neutral-200 bg-white px-2.5 py-1 text-[11px] text-neutral-700","children":"jenkins"}],["$","span","linux",{"className":"rounded-full border border-neutral-200 bg-white px-2.5 py-1 text-[11px] text-neutral-700","children":"linux"}]]}]]}],["$","div",null,{"className":"prose prose-neutral blog-prose max-w-none p-6 sm:p-8 prose-headings:tracking-tight prose-a:text-blue-600 prose-a:no-underline hover:prose-a:underline","dangerouslySetInnerHTML":{"__html":"$3"}}]]}],"$L4"]}]]}],["$L5"],"$L6"]}],"loading":null,"isPartial":false}
4:["$","nav",null,{"className":"mt-8 flex items-center justify-between gap-4 text-sm","children":[["$","div",null,{"children":["$","$L2",null,{"className":"text-neutral-700 hover:underline","href":"/blog/websockets","children":["← ","Accessing websocket data using userscripts"]}]}],["$","div",null,{"className":"text-right","children":["$","$L2",null,{"className":"text-neutral-700 hover:underline","href":"/blog/welcome","children":["Welcome to my blog!"," →"]}]}]]}]
5:["$","script","script-0",{"src":"/openclaw-landing/_next/static/chunks/7c92e96509cd355e.js","async":true}]
6:["$","$L7",null,{"children":["$","$8",null,{"name":"Next.MetadataOutlet","children":"$@9"}]}]
9:null
